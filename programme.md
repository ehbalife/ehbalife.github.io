---
title: Programme
layout: page

menu: true
order: 3
---

## Monday 29th July
**First session: 11:30 to 13:00**\\
11:30-11:45 Introductory talk\\
11:45-12:15 **Keynote speaker 1: Gilbert Roberts.** *The role of reputation in the evolution of cooperation*\\
12:15-12:30 **Chloe Barnes.** *Beyond Goal-Rationality: Traditional Action Can Promote Goal-Achievement in Socially Situated Agents*\\
12:30-12:45 **Elias F. Domingos.** *Timing uncertainty promotes group reciprocity and polarization in the presence of risky commons*\\
12:45-13:00 Contingency time and discussion

**Second session: 14:30 to 16:00**\\
14:30-15:00 **Keynote speaker 2: Peter Lewis.** *What it it like to trust a rock?*\\
15:00-15:30 **Keynote speaker 3: Jasmeen Kanwal.** *Socialising Social Evolution*\\
15:30-15:45 **Jeremy V. Pitt.** *Towards Computational Comparative Politics: modelling the trajectories of political regimes*\\
15:45-16:00 Contingency time and discussion

## Keynote speakers

[Gilbert Roberts](https://www.researchgate.net/profile/Gilbert_Roberts) -- **The role of reputation in the evolution of cooperation**\\
Cooperation is common in nature and is central to human success, but is difficult to explain when it involves individuals helping others at an apparent cost to themselves. Theories of kinship and of reciprocation are well established but cooperation seems to extend well beyond these bounds. Much of my research is on the role of reputation in promoting cooperation. An individual’s reputation in this context is an index of how cooperative it appears to be based on past behaviour. The core idea is that individuals benefit from being seen to be cooperative. Developing a ‘good’ reputation could bring benefits if it influences others to be more cooperative. The most popular theory of how individuals gain is ‘indirect reciprocity’. If X pays some cost (‘cooperates’) to benefit Y, then Z assigns X a good reputation and is more likely to help X in future, so X can make a net profit. I will present some results from agent-based simulations of indirect reciprocity and show how previous conclusions depend crucially on the effects of relatedness. I show how indirect reciprocity is unlikely to be a widespread mechanism accounting for reputation-building. I suggest instead that individuals who display cooperativeness benefit from being more likely to be chosen for social or sexual partnerships. This raises interesting questions about when past generosity is an honest signal of future behaviour, and when individuals should use reputations in choosing partners. I addressed these questions using agent based simulation models in which agents could optionally (1) invest in a cooperative reputation by helping others; (2) choose a partner with a generous reputation; and (3) cooperate in a repeated social dilemma game. I found that these independent traits became linked: reputation was an honest signal of cooperation when it was strategic for cooperators to invest in the benefits of reputation. I conclude that building a cooperative reputation by being generous can be an honest signal of trustworthiness which it pays to attend to when choosing a partner. I suggest that this kind of reputational signalling can help to explain phenomena including philanthropy, collective action, punishment, courtship and advertising.

[Peter Lewis](https://www2.aston.ac.uk/eas/staff/a-z/dr-peter-lewis) -- **What is it like to trust a rock?**\\
We are entering into a world where many of the machines that we are
developing, using, and working with on a day-to-day basis behave in ways
that we neither understand nor can fully control. The complexity
associated with so-called intelligent systems, and how they work, is
fast surpassing human understanding, yet this complexity is often where
their value lies. It is perhaps not surprising, then, that ‘trust’ has
become a hot topic in AI, but what does it mean to trust a machine? Can
machines really be trustworthy? How should we make trust decisions,
given the nature of machines? And should this be the same as the way
humans make decisions when deciding whether to trust other people or
animals, or is it more like the informal way we might talk of trusting a
car to start on a cold morning? After Sloman, I will construct a thought
experiment: ‘what is it like to trust X’, where X may be any of the wide
variety of things animate, inanimate, human, animal, vegetable or
mineral, that are both found and built by people. Our intention is to
propose and illustrate the generality of an integrated model for trust
decisions, and further, to illustrate how instantiations of it vary
between kinds of objects that we might be considering trusting in a
particular context.

[Jasmeen Kanwal](https://jasmeenkanwal.tk) -- **Socialising Social Evolution**\\
In just a couple of decades, the internet has already revolutionised the way we live our daily lives. However, we are still figuring out the role this relatively new technology can play in advancing fundamental science research. In this talk, I discuss how interactive web-based games can be used for two aims: to advance research in the fields of cultural and social evolution through distributed computation and data collection, and to bridge the gap between fundamental science and the public, by allowing the public to easily engage with and participate in research in these fields.

## Contributed extended abstracts

Chloe M. Barnes, Anikó Ekárt and Peter R. Lewis -- [**Beyond Goal-Rationality: Traditional Action Can Promote Goal-Achievement in Socially Situated Agents**](/assets/abstracts/Barnes2019BeyondAgents.pdf)

Elias F. Domingos, Jelena Grujić, Juan C. Burguillo, Georg Kirchsteigher, Francisco C. Santos, and Tom Lenaerts -- [**Timing uncertainty promotes group reciprocity and polarization in the presence of risky commons**](/assets/abstracts/Domingos2019TimingCommons.pdf)

Jeremy V. Pitt, David Burth Kurka and Josiah Ober -- [**Towards Computational Comparative Politics: modelling the trajectories of political regimes**](/assets/asbtracts/Pitt2019TowardsRegimes.pdf)




